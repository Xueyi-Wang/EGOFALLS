# EGOFALLS

Examples of 12 activities, including four kifnds of falls and nine kinds of non-falls.

![videos](https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/eeee875f-ac77-44ec-96f5-95725ff122b7)


# The dataset is under review of dataveerseNL. I will update the link later.

Here is the repository for the dataset of EGOFALLS. EGOFALLS: A visual-audio dataset and benchmark for fall detection using egocentric cameras

Date of data collection: From 2018 to 2022

Location: Groningen, Netherlands

Equipment: Cameras: OnReal G1 (RGB), CAMMHD Bodycams (RGB and Infrared)

Number of subjects: 14 (12 male and 2 female)

Age: 20-60

Location of the camera: Neck and Waist

Environment: Indoor and outdoor

Keywords: Fall detection, multi-modality of vision-audio.

Data and File Overview:

Quantity and type of video clips per participant., where C1 and C2 refer to camera 1 and camera 2, and, 0 means that there is no collection for such activities.

<img width="1108" alt="WX20230908-123836" src="https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/f855201d-8b08-472e-bba5-533b0d43045f">

The primary dataset is archived within individual directories corresponding to each respective subject, as exemplified below:


<img width="786" alt="WX2" src="https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/63960f60-3b3e-4292-9292-d83c25f90076">

Concurrently, the entirety of the data is meticulously preserved within a hierarchical framework, adhering to the subsequent arrangement:

<img width="712" alt="WX3" src="https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/1be4c4ab-fb3f-4107-abc9-74667e671ea9">

The data emanating from each distinct subject is partitioned into more manageable files, each not exceeding 8 GB in size, owing to the constrained upload threshold enforced by the data repository, DataveseNL.
For example for data from S_D_WD:
<img width="789" alt="wx4" src="https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/a3bd812a-2cb4-4524-8ec5-be890f3a84fe">

Then we will have two zip files like the following:

<img width="744" alt="wx5" src="https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/d5192c9d-3ef5-4cfd-b753-6363ec58f1bf">


For Paper "Fall detection with a non-intrusive and first-person vision approach", we only used data from five subjects, since the paper was finished before the complete of the whole dataset. 
